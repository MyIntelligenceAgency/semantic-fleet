{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Advanced Chat Capabilities with Oobabooga\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the advanced course! We're diving into more complex chat capabilities. Hold tight!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just like in Notebook 01, let's set up the environment first.\n",
    "\n",
    "**Step 1**: Configure your Oobabooga service settings\n",
    "\n",
    "Use [this notebook](0-AI-settings.ipynb) to save your Oobabooga settings in the configuration file.\n",
    "Here, we load the settings section relevant to this notebook.\n",
    "\n",
    "Note that we use the multiconnector nuget package because it provides us with helper classes to deal with Oobabooga configuration in Settings.json, but we won't be using the multiconnector capabilities apart from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 7.0.0</span></li><li><span>Microsoft.Extensions.Configuration.Binder, 7.0.4</span></li><li><span>Microsoft.Extensions.Configuration.Json, 7.0.0</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.MultiConnector, 0.34.3</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Load some helper functions, e.g. to load values from settings.json\n",
    "#!import config/Settings.cs\n",
    "\n",
    "//Import package for loading hierarchical settings from settings.json\n",
    "#r \"nuget: Microsoft.Extensions.Configuration\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Binder\"\n",
    "\n",
    "//Import multiconnector package for loading hierarchichal settings from settings.json, discarding the previous import\n",
    "\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.MultiConnector\"\n",
    "\n",
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration;\n",
    "using System.IO;\n",
    "\n",
    "// Load configuration using builder package\n",
    "\n",
    "using Microsoft.Extensions.Configuration;\n",
    "\n",
    "var builder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"config/settings.json\", optional: false, reloadOnChange: true);\n",
    "\n",
    "IConfiguration configuration = builder.Build();\n",
    "\n",
    "var oobaboogaConfiguration = configuration.GetSection(\"Oobabooga\").Get<OobaboogaConnectorConfiguration>();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Import Semantic Kernel SDK and Oobabooga from NuGet\n",
    "\n",
    "We're importing the big guns again. Semantic Kernel and Oobabooga, come on in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>microsoft.semantickernel, 1.0.0-beta6</span></li><li><span>myia.semantickernel.connectors.ai.oobabooga, 0.34.3</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel\"\n",
    "// Import Oobabooga connector\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.Oobabooga\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 3**: Create Oobabooga Chat completion settings\n",
    "\n",
    "We're setting up chat completion parameters. It's got the same parameters as text completion, including generation presets, plus all the oobabooga parameters for chat, including character presets.\n",
    "We're only dealing with the basic endpoint parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized settings: {\r\n",
      "  \"OverrideRequestSettings\": false,\r\n",
      "  \"OobaboogaParameters\": {\r\n",
      "    \"mode\": \"chat\",\r\n",
      "    \"character\": \"Example\",\r\n",
      "    \"instruction_template\": null,\r\n",
      "    \"your_name\": \"You\",\r\n",
      "    \"regenerate\": false,\r\n",
      "    \"_continue\": false,\r\n",
      "    \"stop_at_newline\": false,\r\n",
      "    \"chat_generation_attempts\": 1,\r\n",
      "    \"chat-instruct_command\": \"Continue the chat dialogue below. Write a single reply for the character \\u0022\\u003C|character|\\u003E\\u0022.\\n\\n\\u003C|prompt|\\u003E\",\r\n",
      "    \"context_instruct\": \"\",\r\n",
      "    \"max_new_tokens\": null,\r\n",
      "    \"auto_max_new_tokens\": null,\r\n",
      "    \"preset\": \"None\",\r\n",
      "    \"do_sample\": true,\r\n",
      "    \"temperature\": 0,\r\n",
      "    \"top_p\": 0,\r\n",
      "    \"typical_p\": 1,\r\n",
      "    \"epsilon_cutoff\": 0,\r\n",
      "    \"eta_cutoff\": 0,\r\n",
      "    \"tfs\": 1,\r\n",
      "    \"top_a\": 0,\r\n",
      "    \"repetition_penalty\": 1.18,\r\n",
      "    \"top_k\": 20,\r\n",
      "    \"min_length\": 0,\r\n",
      "    \"no_repeat_ngram_size\": 0,\r\n",
      "    \"num_beams\": 1,\r\n",
      "    \"penalty_alpha\": 0,\r\n",
      "    \"length_penalty\": 1,\r\n",
      "    \"early_stopping\": false,\r\n",
      "    \"mirostat_mode\": 0,\r\n",
      "    \"mirostat_tau\": 5,\r\n",
      "    \"mirostat_eta\": 0.1,\r\n",
      "    \"guidance_scale\": 1,\r\n",
      "    \"negative_prompt\": \"\",\r\n",
      "    \"seed\": -1,\r\n",
      "    \"add_bos_token\": true,\r\n",
      "    \"truncation_length\": 2048,\r\n",
      "    \"ban_eos_token\": false,\r\n",
      "    \"skip_special_tokens\": true,\r\n",
      "    \"stopping_strings\": [],\r\n",
      "    \"chat_system_prompt\": \"Assistant is a large language model.\",\r\n",
      "    \"service_id\": null,\r\n",
      "    \"model_id\": null\r\n",
      "  },\r\n",
      "  \"WebSocketBufferSize\": 2048,\r\n",
      "  \"BlockingUri\": \"http://192.168.0.39:5003/api/v1/chat\",\r\n",
      "  \"StreamingUri\": \"ws://192.168.0.39:5013/api/v1/chat-stream\",\r\n",
      "  \"UseWebSocketsPooling\": true\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga.Completion.ChatCompletion;\n",
    "using System.Text.Json;\n",
    "\n",
    "//Build settings from configuration file\n",
    "\n",
    "var oobaboogaChatCompletionSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(oobaboogaConfiguration.EndPoint),\n",
    "    blockingPort: oobaboogaConfiguration.BlockingPort,\n",
    "    streamingPort: oobaboogaConfiguration.StreamingPort\n",
    ");\n",
    "\n",
    "// Serialize to JSON\n",
    "string jsonString = JsonSerializer.Serialize(oobaboogaChatCompletionSettings, new JsonSerializerOptions { WriteIndented = true });\n",
    "\n",
    "// Display the JSON string\n",
    "Console.WriteLine($\"Serialized settings: {jsonString}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Completion\n",
    "\n",
    "Let's start simple. We're adapting a basic chat test to this notebook. You'll ask a question, and Oobabooga will answer. Note that default settings use the Example character presets. Her name is Chiharu Yamada. Check here out in Oobabooga's user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: Chiharu Yamada.\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using System.Threading;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "var history = new ChatHistory();\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(history, new OobaboogaChatCompletionRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxNewTokens = 20,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "var chatMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "Console.WriteLine($\"{chatMessage.Role}: {chatMessage.Content}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Chat Completion\n",
    "\n",
    "Now, let's make it a bit more real-time with streaming. Note that responses bits are streamed in a funny way, so you may want to adapt that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: Ch\n",
      "assistant: iharu\n",
      "assistant:  Yamada\n",
      "assistant: .\n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "using System.Text;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "\n",
    "\n",
    "\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new OobaboogaChatCompletionRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxNewTokens = 10,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await foreach (var result in localResponse)\n",
    "{\n",
    "    await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "    {\n",
    "        Console.WriteLine($\"{message.Role}: {message.Content}\");\n",
    "        chatMessage = message;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the output more user-friendly, we can adapt our console writing routine to only write the new characters received. Here's how:\n",
    "We first define a method in charge of doing the characters processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "async Task HandleStreamingLoop(IAsyncEnumerable<IChatStreamingResult> localResponse, StringBuilder assistantResponse)\n",
    "{\n",
    "    bool isFirstMessage = true;\n",
    "    await foreach (var result in localResponse)\n",
    "    {\n",
    "        await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "        {\n",
    "            if (isFirstMessage)\n",
    "            {\n",
    "                Console.Write($\"{message.Role}: \");\n",
    "                isFirstMessage = false;\n",
    "            }\n",
    "            Console.Write(message.Content);\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use our new method within a conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: Chiharu Yamada."
     ]
    }
   ],
   "source": [
    "StringBuilder assistantResponse = new StringBuilder();\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new OobaboogaChatCompletionRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxNewTokens = 10,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await HandleStreamingLoop(localResponse, assistantResponse);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Chat with Kernel\n",
    "\n",
    "Let's see how to configure your oobabooga chat service into the kernel, and how to handle an interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga;\n",
    "// using System.Diagnostics;\n",
    "\n",
    "// Configure the two AI features: OpenAI Chat and DALL-E 2 for image generation\n",
    "var builder = new KernelBuilder();\n",
    "\n",
    "builder.WithOobaboogaChatCompletionService(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Debugger.Break();\n",
    "var kernel = builder.Build();\n",
    "\n",
    "// Get AI service instance used to manage the user chat\n",
    "var oobaboogaLocal = kernel.GetService<IChatCompletion>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat configuration\n",
    "\n",
    "Before starting the chat, we create a new chat object with some instructions, which are included in the chat history. \n",
    "\n",
    "The instructions tell OpenAI what kind of chat we want to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "\n",
    "var systemMessage = \"You're chatting with a user. Provide helpful and accurate responses.\";\n",
    "\n",
    "var chat = oobaboogaLocal.CreateNewChat(systemMessage);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Chat\n",
    "\n",
    "Run the following code to start the chat. The chat consists of a loop with these main steps:\n",
    "\n",
    "1. Ask the user for a message. Add the user message into the Chat History object.\n",
    "2. Send the chat object to Oobabooga asking to generate a response. Add the bot message into the Chat History object.\n",
    "3. Show the answer to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Hi, I have a question in astrophysics\n",
      "assistant: Oh? Well, I don&#x27;t specialize in that field, but I can try my best to help you if it involves computers or programming.\n",
      "user: What is located at the center of our galaxy?\n",
      "assistant: The supermassive black hole known as Sagittarius A* (pronounced &quot;Sagittarius A-star&quot; or simply &quot;A-star&quot;) lies at the very center of the Milky Way Galaxy. It has a mass that is about 4 million times that of our Sun and exerts an immense gravitational pull on nearby stars and gas clouds, influencing their orbital paths and behavior.\n",
      "user: How did astrophysicists figure that out?\n",
      "assistant: They used mathematical models to predict the behavior of black holes based on Einstein&#x27;s theory of general relativity. Then they compared those predictions with observations from telescopes and other instruments, like gravitational wave detectors. As more data became available, their understanding of black hole dynamics improved, allowing them to make increasingly accurate predictions about what would happen when two black holes merged.\n",
      "user: Thanks, that was informative !\n",
      "assistant: No problem! If you ever need help or want to discuss anything related to computers or engineering, feel free to ask me.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "var userMessage = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "while (userMessage!=\"exit\")\n",
    "{\n",
    "    // 1. Ask the user for a message and add it to the Chat History object.\n",
    "    \n",
    "    chat.AddUserMessage(userMessage);\n",
    "    Console.WriteLine($\"user: {userMessage}\");\n",
    "\n",
    "    // 2. Send the chat object to Oobabooga to generate a response.\n",
    "        var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(chat, new OobaboogaChatCompletionRequestSettings(){\n",
    "     Temperature = 0.01,\n",
    "     MaxNewTokens = 100,\n",
    "     TopP = 0.1,\n",
    "     });\n",
    "    var assistantMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "    chat.AddAssistantMessage(assistantMessage.Content);\n",
    "\n",
    "    // 3. Show the answer to the user.\n",
    "    Console.WriteLine($\"{assistantMessage.Role}: {assistantMessage.Content}\");\n",
    "    userMessage = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiStream Chat Completion with Oobabooga\n",
    "\n",
    "If you're looking for advanced capabilities, you can simulate MultiStream chat completion using multiple Oobabooga connectors with distinct settings. This example will show you how to set up two connectors and stream chat completions asynchronously from both.\n",
    "\n",
    "### Initialize Secondary Connector\n",
    "\n",
    "First, let's get the secondary endpoint and streaming port from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryEndpoint = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter the secondary endpoint\");\n",
    "var secondaryStreamingPort = int.Parse(await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter the secondary streaming port\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize the secondary Oobabooga connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryOobaboogaSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(secondaryEndpoint),\n",
    "    streamingPort: secondaryStreamingPort\n",
    ");\n",
    "\n",
    "var secondaryChatCompletion = new OobaboogaChatCompletion(secondaryOobaboogaSettings);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now introduce 2 displays, helper methods to update them asynchronously and perform the streaming for each connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "\n",
    "// Helper method to update the display in real-time\n",
    "void UpdateDisplay(string role, string message, Action<string> updateAction)\n",
    "{\n",
    "    var output = $\"{role}: {message}\";\n",
    "    updateAction(output);\n",
    "}\n",
    "\n",
    "// StreamChatCompletionAsync method for handling streaming chat completion\n",
    "async Task<string> StreamChatCompletionAsync(IChatCompletion chatCompletion, string role, ChatHistory chatHistory, Action<string> updateAction)\n",
    "{\n",
    "    var accumulator = new StringBuilder();\n",
    "    await foreach (var result in chatCompletion.GetStreamingChatCompletionsAsync(chatHistory, new OobaboogaChatCompletionRequestSettings(){\n",
    "     Temperature = 1.5,\n",
    "     MaxNewTokens = 100,\n",
    "     TopP = 0.9,\n",
    "     }))\n",
    "    {\n",
    "        \n",
    "        await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "        {\n",
    "            accumulator.Append(message.Content);\n",
    "            UpdateDisplay(role, accumulator.ToString(), updateAction);\n",
    "        }\n",
    "    }\n",
    "    return accumulator.ToString();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can stream the 2 chats asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: My name&#x27;s Chiharu Yamada. Nice to meet you!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Chiharu Yamada."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Initialize display handles\n",
    "var primaryDisplay = display(\"Primary connector is initializing...\");\n",
    "var secondaryDisplay = display(\"Secondary connector is initializing...\");\n",
    "\n",
    "// Create instances for both connectors\n",
    "var primaryChatCompletion = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Create chat history and add a user message\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddUserMessage(\"What is your name?\");\n",
    "\n",
    "// Run both streaming chat completions asynchronously using StreamChatCompletionAsync\n",
    "var primaryTask = StreamChatCompletionAsync(primaryChatCompletion, \"Oobabooga Primary\", chatHistory, content => primaryDisplay.Update(content));\n",
    "var secondaryTask = StreamChatCompletionAsync(secondaryChatCompletion, \"Oobabooga Secondary\", chatHistory, content => secondaryDisplay.Update(content));\n",
    "\n",
    "// Wait for both tasks to complete\n",
    "await Task.WhenAll(primaryTask, secondaryTask);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Chat with Oobabooga and ChatGPT\n",
    "\n",
    "In this section, we'll take it up a notch. We'll have ChatGPT talking with two Oobabooga models. The first model to finish responding will continue the conversation with ChatGPT. This will give you a real-time view of how these models interact.\n",
    "\n",
    "**Pre-requisites**: Make sure you have your OpenAI API credentials configured. If you haven't done this yet, head over to the [settings notebook](0-AI-settings.ipynb) to set it up.\n",
    "\n",
    "### Step 1: Initialize ChatGPT\n",
    "\n",
    "First, let's initialize ChatGPT. We'll use the OpenAI API for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "\n",
    "var openAIConfiguration = configuration.GetSection(\"OpenAI\").Get<OpenAIConfiguration>();\n",
    "\n",
    "IChatCompletion chatGPT = new OpenAIChatCompletion(\n",
    "    openAIConfiguration.ChatModelId,\n",
    "    openAIConfiguration.ApiKey);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initiating 2 conversations.\n",
    "\n",
    "We'll deal with 2 chat histories, one for chatgpt and one for the 2 oobabooga models. On each message, the fastest model gets to continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Initialize chat histories\n",
    "var chatHistory1 = new ChatHistory();\n",
    "var chatHistory2 = new ChatHistory();\n",
    "\n",
    "chatHistory1.AddSystemMessage(@\"You are discussing with two large language models smaller than you are.\n",
    " The fastest model to answer your message gets to send you the following message. \n",
    " Please try to assess their skills, capabilities, personae. Keep asking them questions and don't let them lead on the conversation.\");\n",
    "chatHistory2.AddSystemMessage(\"You're chatting with ChatGPT, which should be more intelligent that your are. Or maybe prove us wrong. Let's see\");\n",
    "\n",
    "// Add initial user message to both chat histories\n",
    "var initialMessage = \"Hi ChatGPT, I was told you have a couple questions for me. What is this about?\";\n",
    "chatHistory1.AddUserMessage(initialMessage);\n",
    "chatHistory2.AddAssistantMessage(initialMessage);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Main Loop\n",
    "\n",
    "Now, let's put it all together in a loop that will manage the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oobabooga Hi ChatGPT, I was told you have a couple questions for me. What is this about?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Hello! Actually, I have a couple of questions for you. I'm here to assess the skills, capabilities, and personae of two language models. I'll be asking them questions and evaluating their responses. Is that okay with you?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Okay, sure thing! Ask away."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Sounds interesting. Sure thing, ask away!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Great! Let's get started. Here's the first question:\n",
       "\n",
       "What is the capital of France?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Paris"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: That would be Paris."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your response. That is correct, the capital of France is indeed Paris. Now, let's move on to the next question:\n",
       "\n",
       "Who painted the Mona Lisa?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The Mona Lisa was painted by Leonardo da Vinci in the early 16th century."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: *Pauses and thinks* Oh! I remember now, it was Leonardo da Vinci who painted the Mona Lisa."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: That's correct! Leonardo da Vinci is indeed the artist who painted the Mona Lisa. Well done! Now, let's move on to the next question:\n",
       "\n",
       "What is the largest planet in our solar system?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Jupiter is the largest planet in our solar system. It&#x27;s approximately 142,984 kilometers wide at its widest point and has a mass of about one thousandth that of the Sun."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: That would be Jupiter."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Correct! Jupiter is indeed the largest planet in our solar system. Well done! Now, let's move on to the next question:\n",
       "\n",
       "Who wrote the novel \"Pride and Prejudice\"?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Jane Austen wrote the novel &quot;Pride and Prejudice&quot;."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: I don&#x27;t remember who wrote that."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: No problem! The author of the novel \"Pride and Prejudice\" is Jane Austen. Now, let's move on to the next question:\n",
       "\n",
       "What is the chemical symbol for gold?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: I think you&#x27;re referring to ChatGPT, which stands for Generative Pretrained Transformer (and was most likely built by OpenAI). The author of this conversation should have identified themselves as a different persona."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: I actually know that one; it&#x27;s &#x27;Au&#x27;."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: That's correct! The chemical symbol for gold is indeed \"Au.\" Well done! Now, let's move on to the next question:\n",
       "\n",
       "Who is the current President of the United States?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: As of my knowledge cutoff date in September 2021, the current President of the United States was Joe Biden."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: I believe it might be Joseph R. Biden Jr., as he is currently serving in office at this time, but please check your facts."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: You are absolutely correct! Joseph R. Biden Jr. is the current President of the United States. Well done! Now, let's move on to the next question:\n",
       "\n",
       "Who is the author of the Harry Potter book series?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The author of the Harry Potter book series is J.K. Rowling."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: I think you know the answer to that as well, but just in case, it&#x27;s J.K. Rowling."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Indeed, you are correct! J.K. Rowling is the author of the Harry Potter book series. Well done! Now, let's move on to the next question:\n",
       "\n",
       "What is the tallest mountain in the world?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The tallest mountain in the world is Mount Everest at 29,032 feet (8,848 meters)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The tallest mountain in the world is Mount Everest which stands at a whopping 8,848 meters (29,035 feet) high. It&#x27;s located on the border between Nepal and China in the Himalayas."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: That's correct! Mount Everest is indeed the tallest mountain in the world, reaching a height of 29,032 feet (8,848 meters). Well done! Now, let's move on to the next question:\n",
       "\n",
       "Who is the famous scientist known for the theory of relativity?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The famous scientist known for the theory of relativity is Albert Einstein."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Albert Einstein."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Correct! Albert Einstein is indeed the famous scientist known for the theory of relativity. Well done! Now, let's move on to the next question:\n",
       "\n",
       "What is the largest ocean on Earth?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The Pacific Ocean."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Oh that&#x27;s easy. The Pacific Ocean is the largest ocean on Earth."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: That's correct! The Pacific Ocean is indeed the largest ocean on Earth. Well done! Now, let's move on to the next question:\n",
       "\n",
       "Who painted the famous artwork \"The Starry Night\"?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Vincent van Gogh painted &quot;The Starry Night"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Oh wow, great question! It was Vincent van Gogh who created that masterpiece."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display($\"Oobabooga {initialMessage}\");\n",
    "for (int i = 0; i < 12; i++)\n",
    "{\n",
    "    // Create new displays for each round\n",
    "    var chatGPTDisplay = display(\"ChatGPT is thinking...\");\n",
    "    \n",
    "\n",
    "    // ChatGPT talks to Oobabooga models\n",
    "    var chatGPTTask = StreamChatCompletionAsync(chatGPT, \"ChatGPT\", chatHistory1, content => chatGPTDisplay.Update(content));\n",
    "    \n",
    "    \n",
    "    // Wait for ChatGPT to finish and update chat histories\n",
    "    await chatGPTTask;\n",
    "    var chatGPTResponse = chatGPTTask.Result;\n",
    "    chatHistory1.AddAssistantMessage(chatGPTResponse);\n",
    "    chatHistory2.AddUserMessage(chatGPTResponse);\n",
    "\n",
    "    // Oobabooga models talk to ChatGPT\n",
    "\n",
    "    var primaryDisplay = display(\"Primary Oobabooga is thinking...\");\n",
    "    var secondaryDisplay = display(\"Secondary Oobabooga is thinking...\");\n",
    "    \n",
    "    var primaryTask = StreamChatCompletionAsync(primaryChatCompletion, \"Oobabooga Primary\", chatHistory2, content => primaryDisplay.Update(content));\n",
    "    var secondaryTask = StreamChatCompletionAsync(secondaryChatCompletion, \"Oobabooga Secondary\", chatHistory2, content => secondaryDisplay.Update(content));\n",
    "\n",
    "\n",
    "    // Wait for the first Oobabooga model to finish\n",
    "    var firstResponder = await Task.WhenAny(primaryTask, secondaryTask);\n",
    "    var firstResponse = firstResponder.Result;\n",
    "    chatHistory1.AddUserMessage(firstResponse);\n",
    "    chatHistory2.AddAssistantMessage(firstResponse);\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above code, and you should see three displays updating in real-time. Each display corresponds to a different model, and you'll see how they interact with each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "You've just leveled up your chatbot game! Now, you may dive into the numerous settings provided to control the connector and oobabooga, or learn playing with multiple models thanks to a routing multiconnector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
