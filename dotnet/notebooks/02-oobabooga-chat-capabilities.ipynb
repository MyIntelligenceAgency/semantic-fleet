{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Advanced Chat Capabilities with Oobabooga\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the advanced course! We're diving into more complex chat capabilities. Hold tight!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just like in Notebook 01, let's set up the environment first.\n",
    "\n",
    "**Step 1**: Configure your Oobabooga service settings\n",
    "\n",
    "Use [this notebook](0-AI-settings.ipynb) to save your Oobabooga settings in the configuration file.\n",
    "Here, we load the settings section relevant to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Load some helper functions, e.g. to load values from settings.json\n",
    "#!import config/Settings.cs\n",
    "\n",
    "//Import package for loading hierarchichal settings from settings.json\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, 8.0.0-rc.1.23419.4\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 8.0.0-rc.1.23419.4\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Binder, 8.0.0-rc.1.23419.4\"\n",
    "\n",
    "#!import config/OobaboogaConnectorConfiguration.cs\n",
    "\n",
    "// Load configuration using builder package\n",
    "\n",
    "using Microsoft.Extensions.Configuration;\n",
    "\n",
    "var builder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"config/settings.json\", optional: false, reloadOnChange: true);\n",
    "\n",
    "IConfiguration configuration = builder.Build();\n",
    "\n",
    " var oobaboogaConfiguration = configuration.GetSection(\"Oobabooga\").Get<OobaboogaConnectorConfiguration>();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Import Semantic Kernel SDK and Oobabooga from NuGet\n",
    "\n",
    "We're importing the big guns again. Semantic Kernel and Oobabooga, come on in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 0.24.230918.1-preview\"\n",
    "// Import Oobabooga connector\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.Oobabooga,  0.33.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 3**: Create Oobabooga Chat completion settings\n",
    "\n",
    "We're setting up chat completion parameters. It's got the same parameters as text completion, including generation presets, plus all the oobabooga parameters for chat, including character presets.\n",
    "We're only dealing with the basic endpoint parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga.Completion.ChatCompletion;\n",
    "\n",
    "//Build settings from configuration file\n",
    "\n",
    "var oobaboogaChatCompletionSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(oobaboogaConfiguration.EndPoint),\n",
    "    blockingPort: oobaboogaConfiguration.BlockingPort,\n",
    "    streamingPort: oobaboogaConfiguration.StreamingPort\n",
    ");\n",
    "\n",
    "// Serialize to JSON\n",
    "//string jsonString = JsonSerializer.Serialize(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Display the JSON string\n",
    "//Console.WriteLine($\"Serialized settings: {jsonString}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Completion\n",
    "\n",
    "Let's start simple. We're adapting a basic chat test to this notebook. You'll ask a question, and Oobabooga will answer. Note that default settings use the Example character presets. Her name is Chiharu Yamada. Check here out in Oobabooga's user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using System.Threading;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "var history = new ChatHistory();\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 20,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "var chatMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "Console.WriteLine($\"{chatMessage.Role}: {chatMessage.Content}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Chat Completion\n",
    "\n",
    "Now, let's make it a bit more real-time with streaming. Note that responses bits are streamed in a funny way, so you may want to adapt that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.Text;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "\n",
    "\n",
    "\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 7,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await foreach (var result in localResponse)\n",
    "{\n",
    "    await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "    {\n",
    "        Console.WriteLine($\"{message.Role}: {message.Content}\");\n",
    "        chatMessage = message;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the output more user-friendly, we can adapt our console writing routine to only write the new characters received. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.Text;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "\n",
    "StringBuilder assistantResponse = new StringBuilder();\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "bool isFirstMessage = true;\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 7,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await foreach (var result in localResponse)\n",
    "{\n",
    "    await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "    {\n",
    "        if (isFirstMessage)\n",
    "        {\n",
    "            Console.Write($\"{message.Role}: {message.Content}\");\n",
    "            assistantResponse.Append(message.Content);\n",
    "            isFirstMessage = false;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            // Append only the new characters to the existing assistant's response\n",
    "            var newChars = message.Content.Substring(assistantResponse.Length);\n",
    "            assistantResponse.Append(newChars);\n",
    "            \n",
    "            // Write the new characters to the console\n",
    "            Console.Write(newChars);\n",
    "        }\n",
    "        \n",
    "        chatMessage = message;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Chat with Kernel\n",
    "\n",
    "Let's see how to configure your oobabooga chat service into the kernel, and how to handle an interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga;\n",
    "// using System.Diagnostics;\n",
    "\n",
    "// Configure the two AI features: OpenAI Chat and DALL-E 2 for image generation\n",
    "var builder = new KernelBuilder();\n",
    "\n",
    "builder.WithOobaboogaChatCompletionService(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Debugger.Break();\n",
    "var kernel = builder.Build();\n",
    "\n",
    "// Get AI service instance used to manage the user chat\n",
    "var oobaboogaLocal = kernel.GetService<IChatCompletion>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat configuration\n",
    "\n",
    "Before starting the chat, we create a new chat object with some instructions, which are included in the chat history. \n",
    "\n",
    "The instructions tell OpenAI what kind of chat we want to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "\n",
    "var systemMessage = \"You're chatting with a user. Provide helpful and accurate responses.\";\n",
    "\n",
    "var chat = oobaboogaLocal.CreateNewChat(systemMessage);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Chat\n",
    "\n",
    "Run the following code to start the chat. The chat consists of a loop with these main steps:\n",
    "\n",
    "1. Ask the user for a message. Add the user message into the Chat History object.\n",
    "2. Send the chat object to Oobabooga asking to generate a response. Add the bot message into the Chat History object.\n",
    "3. Show the answer to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var userMessage = await InteractiveKernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "while (userMessage!=\"exit\")\n",
    "{\n",
    "    // 1. Ask the user for a message and add it to the Chat History object.\n",
    "    \n",
    "    chat.AddUserMessage(userMessage);\n",
    "    Console.WriteLine($\"user: {userMessage}\");\n",
    "\n",
    "    // 2. Send the chat object to Oobabooga to generate a response.\n",
    "        var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(chat, new ChatRequestSettings(){\n",
    "     Temperature = 0.01,\n",
    "     MaxTokens = 20,\n",
    "     TopP = 0.1,\n",
    "     });\n",
    "    var assistantMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "    chat.AddAssistantMessage(assistantMessage.Content);\n",
    "\n",
    "    // 3. Show the answer to the user.\n",
    "    Console.WriteLine($\"{assistantMessage.Role}: {assistantMessage.Content}\");\n",
    "    userMessage = await InteractiveKernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiStream Chat Completion with Oobabooga\n",
    "\n",
    "If you're looking for advanced capabilities, you can simulate MultiStream chat completion using multiple Oobabooga connectors with distinct settings. This example will show you how to set up two connectors and stream chat completions asynchronously from both.\n",
    "\n",
    "### Initialize Secondary Connector\n",
    "\n",
    "First, let's get the secondary endpoint and streaming port from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryEndpoint = await InteractiveKernel.GetInputAsync(\"Enter the secondary endpoint\");\n",
    "var secondaryStreamingPort = int.Parse(await InteractiveKernel.GetInputAsync(\"Enter the secondary streaming port\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize the secondary Oobabooga connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryOobaboogaSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(secondaryEndpoint),\n",
    "    streamingPort: secondaryStreamingPort\n",
    ");\n",
    "\n",
    "var secondaryChatCompletion = new OobaboogaChatCompletion(secondaryOobaboogaSettings);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now introduce 2 displays, helper methods to update them asynchronously and perform the streaming for each connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "\n",
    "// Helper method to update the display in real-time\n",
    "void UpdateDisplay(string role, string message, Action<string> updateAction)\n",
    "{\n",
    "    var output = $\"{role}: {message}\";\n",
    "    updateAction(output);\n",
    "}\n",
    "\n",
    "// StreamChatCompletionAsync method for handling streaming chat completion\n",
    "async Task StreamChatCompletionAsync(OobaboogaChatCompletion chatCompletion, ChatHistory chatHistory, Action<string> updateAction)\n",
    "{\n",
    "    await foreach (var result in chatCompletion.GetStreamingChatCompletionsAsync(chatHistory, new ChatRequestSettings(){\n",
    "     Temperature = 0.01,\n",
    "     MaxTokens = 20,\n",
    "     TopP = 0.1,\n",
    "     }))\n",
    "    {\n",
    "        await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "        {\n",
    "            UpdateDisplay(\"Connector\", message.Content, updateAction);\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can stream the 2 chats asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Initialize display handles\n",
    "var primaryDisplay = display(\"Primary connector is initializing...\");\n",
    "var secondaryDisplay = display(\"Secondary connector is initializing...\");\n",
    "\n",
    "// Create instances for both connectors\n",
    "var primaryChatCompletion = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Create chat history and add a user message\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddUserMessage(\"What is your name?\");\n",
    "\n",
    "// Run both streaming chat completions asynchronously using StreamChatCompletionAsync\n",
    "var primaryTask = StreamChatCompletionAsync(primaryChatCompletion, chatHistory, content => primaryDisplay.Update(content));\n",
    "var secondaryTask = StreamChatCompletionAsync(secondaryChatCompletion, chatHistory, content => secondaryDisplay.Update(content));\n",
    "\n",
    "// Wait for both tasks to complete\n",
    "await Task.WhenAll(primaryTask, secondaryTask);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "You've just leveled up your chatbot game! Now, you may dive into the numerous settings provided to control the connector and oobabooga, or learn playing with multiple models thanks to a routing multiconnector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
