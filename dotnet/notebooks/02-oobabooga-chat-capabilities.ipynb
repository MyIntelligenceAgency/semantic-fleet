{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Advanced Chat Capabilities with Oobabooga\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the advanced course! We're diving into more complex chat capabilities. Hold tight!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just like in Notebook 01, let's set up the environment first.\n",
    "\n",
    "**Step 1**: Configure your Oobabooga service settings\n",
    "\n",
    "Use [this notebook](0-AI-settings.ipynb) to save your Oobabooga settings in the configuration file.\n",
    "Here, we load the settings section relevant to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 8.0.0-rc.1.23419.4</span></li><li><span>Microsoft.Extensions.Configuration.Binder, 8.0.0-rc.1.23419.4</span></li><li><span>Microsoft.Extensions.Configuration.Json, 8.0.0-rc.1.23419.4</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Load some helper functions, e.g. to load values from settings.json\n",
    "#!import config/Settings.cs\n",
    "\n",
    "//Import package for loading hierarchichal settings from settings.json\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, 8.0.0-rc.1.23419.4\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 8.0.0-rc.1.23419.4\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Binder, 8.0.0-rc.1.23419.4\"\n",
    "\n",
    "#!import config/OobaboogaConnectorConfiguration.cs\n",
    "\n",
    "// Load configuration using builder package\n",
    "\n",
    "using Microsoft.Extensions.Configuration;\n",
    "\n",
    "var builder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"config/settings.json\", optional: false, reloadOnChange: true);\n",
    "\n",
    "IConfiguration configuration = builder.Build();\n",
    "\n",
    " var oobaboogaConfiguration = configuration.GetSection(\"Oobabooga\").Get<OobaboogaConnectorConfiguration>();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Import Semantic Kernel SDK and Oobabooga from NuGet\n",
    "\n",
    "We're importing the big guns again. Semantic Kernel and Oobabooga, come on in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 0.24.230918.1-preview</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.Oobabooga, 0.33.3</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 0.24.230918.1-preview\"\n",
    "// Import Oobabooga connector\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.Oobabooga,  0.33.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 3**: Create Oobabooga Chat completion settings\n",
    "\n",
    "We're setting up chat completion parameters. It's got the same parameters as text completion, including generation presets, plus all the oobabooga parameters for chat, including character presets.\n",
    "We're only dealing with the basic endpoint parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga.Completion.ChatCompletion;\n",
    "\n",
    "//Build settings from configuration file\n",
    "\n",
    "var oobaboogaChatCompletionSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(oobaboogaConfiguration.EndPoint),\n",
    "    blockingPort: oobaboogaConfiguration.BlockingPort,\n",
    "    streamingPort: oobaboogaConfiguration.StreamingPort\n",
    ");\n",
    "\n",
    "// Serialize to JSON\n",
    "//string jsonString = JsonSerializer.Serialize(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Display the JSON string\n",
    "//Console.WriteLine($\"Serialized settings: {jsonString}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Completion\n",
    "\n",
    "Let's start simple. We're adapting a basic chat test to this notebook. You'll ask a question, and Oobabooga will answer. Note that default settings use the Example character presets. Her name is Chiharu Yamada. Check here out in Oobabooga's user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: My name is Chiharu Yamada.\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using System.Threading;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "var history = new ChatHistory();\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 20,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "var chatMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "Console.WriteLine($\"{chatMessage.Role}: {chatMessage.Content}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Chat Completion\n",
    "\n",
    "Now, let's make it a bit more real-time with streaming. Note that responses bits are streamed in a funny way, so you may want to adapt that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: My\n",
      "assistant:  name is\n",
      "assistant:  Chih\n",
      "assistant: aru Yam\n",
      "assistant: \n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "using System.Text;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "\n",
    "\n",
    "\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 7,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await foreach (var result in localResponse)\n",
    "{\n",
    "    await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "    {\n",
    "        Console.WriteLine($\"{message.Role}: {message.Content}\");\n",
    "        chatMessage = message;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the output more user-friendly, we can adapt our console writing routine to only write the new characters received. Here's how:\n",
    "We first define a method in charge of doing the characters processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "async Task HandleStreamingLoop(IAsyncEnumerable<IChatStreamingResult> localResponse, StringBuilder assistantResponse)\n",
    "{\n",
    "    bool isFirstMessage = true;\n",
    "    await foreach (var result in localResponse)\n",
    "    {\n",
    "        await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "        {\n",
    "            if (isFirstMessage)\n",
    "            {\n",
    "                Console.Write($\"{message.Role}: \");\n",
    "                isFirstMessage = false;\n",
    "            }\n",
    "            Console.Write(message.Content);\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use our new method within a conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is your name?\n",
      "assistant: My name is Chiharu Yam"
     ]
    }
   ],
   "source": [
    "StringBuilder assistantResponse = new StringBuilder();\n",
    "ChatMessageBase? chatMessage = null;\n",
    "\n",
    "var oobaboogaLocal = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "var history = new ChatHistory();\n",
    "\n",
    "var message = \"What is your name?\";\n",
    "history.AddUserMessage(message);\n",
    "Console.WriteLine($\"user: {message}\");\n",
    "\n",
    "var localResponse = oobaboogaLocal.GetStreamingChatCompletionsAsync(history, new ChatRequestSettings()\n",
    "{\n",
    "    Temperature = 0.01,\n",
    "    MaxTokens = 7,\n",
    "    TopP = 0.1,\n",
    "});\n",
    "\n",
    "await HandleStreamingLoop(localResponse, assistantResponse);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Chat with Kernel\n",
    "\n",
    "Let's see how to configure your oobabooga chat service into the kernel, and how to handle an interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.AI.ChatCompletion;\n",
    "using MyIA.SemanticKernel.Connectors.AI.Oobabooga;\n",
    "// using System.Diagnostics;\n",
    "\n",
    "// Configure the two AI features: OpenAI Chat and DALL-E 2 for image generation\n",
    "var builder = new KernelBuilder();\n",
    "\n",
    "builder.WithOobaboogaChatCompletionService(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Debugger.Break();\n",
    "var kernel = builder.Build();\n",
    "\n",
    "// Get AI service instance used to manage the user chat\n",
    "var oobaboogaLocal = kernel.GetService<IChatCompletion>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat configuration\n",
    "\n",
    "Before starting the chat, we create a new chat object with some instructions, which are included in the chat history. \n",
    "\n",
    "The instructions tell OpenAI what kind of chat we want to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "\n",
    "var systemMessage = \"You're chatting with a user. Provide helpful and accurate responses.\";\n",
    "\n",
    "var chat = oobaboogaLocal.CreateNewChat(systemMessage);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Chat\n",
    "\n",
    "Run the following code to start the chat. The chat consists of a loop with these main steps:\n",
    "\n",
    "1. Ask the user for a message. Add the user message into the Chat History object.\n",
    "2. Send the chat object to Oobabooga asking to generate a response. Add the bot message into the Chat History object.\n",
    "3. Show the answer to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Hi, what are you up to?\n",
      "assistant: Oh, just working on a new project for a client.\n"
     ]
    }
   ],
   "source": [
    "var userMessage = await InteractiveKernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "while (userMessage!=\"exit\")\n",
    "{\n",
    "    // 1. Ask the user for a message and add it to the Chat History object.\n",
    "    \n",
    "    chat.AddUserMessage(userMessage);\n",
    "    Console.WriteLine($\"user: {userMessage}\");\n",
    "\n",
    "    // 2. Send the chat object to Oobabooga to generate a response.\n",
    "        var localResponse = await oobaboogaLocal.GetChatCompletionsAsync(chat, new ChatRequestSettings(){\n",
    "     Temperature = 0.01,\n",
    "     MaxTokens = 20,\n",
    "     TopP = 0.1,\n",
    "     });\n",
    "    var assistantMessage = await localResponse[^1].GetChatMessageAsync(CancellationToken.None).ConfigureAwait(false);\n",
    "    chat.AddAssistantMessage(assistantMessage.Content);\n",
    "\n",
    "    // 3. Show the answer to the user.\n",
    "    Console.WriteLine($\"{assistantMessage.Role}: {assistantMessage.Content}\");\n",
    "    userMessage = await InteractiveKernel.GetInputAsync(\"Your message (or type 'exit' to exit)\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiStream Chat Completion with Oobabooga\n",
    "\n",
    "If you're looking for advanced capabilities, you can simulate MultiStream chat completion using multiple Oobabooga connectors with distinct settings. This example will show you how to set up two connectors and stream chat completions asynchronously from both.\n",
    "\n",
    "### Initialize Secondary Connector\n",
    "\n",
    "First, let's get the secondary endpoint and streaming port from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryEndpoint = await InteractiveKernel.GetInputAsync(\"Enter the secondary endpoint\");\n",
    "var secondaryStreamingPort = int.Parse(await InteractiveKernel.GetInputAsync(\"Enter the secondary streaming port\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize the secondary Oobabooga connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var secondaryOobaboogaSettings = new OobaboogaChatCompletionSettings(\n",
    "    endpoint: new Uri(secondaryEndpoint),\n",
    "    streamingPort: secondaryStreamingPort\n",
    ");\n",
    "\n",
    "var secondaryChatCompletion = new OobaboogaChatCompletion(secondaryOobaboogaSettings);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now introduce 2 displays, helper methods to update them asynchronously and perform the streaming for each connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "\n",
    "// Helper method to update the display in real-time\n",
    "void UpdateDisplay(string role, string message, Action<string> updateAction)\n",
    "{\n",
    "    var output = $\"{role}: {message}\";\n",
    "    updateAction(output);\n",
    "}\n",
    "\n",
    "// StreamChatCompletionAsync method for handling streaming chat completion\n",
    "async Task<string> StreamChatCompletionAsync(IChatCompletion chatCompletion, string role, ChatHistory chatHistory, Action<string> updateAction)\n",
    "{\n",
    "    var accumulator = new StringBuilder();\n",
    "    await foreach (var result in chatCompletion.GetStreamingChatCompletionsAsync(chatHistory, new ChatRequestSettings(){\n",
    "     Temperature = 0.01,\n",
    "     MaxTokens = 100,\n",
    "     TopP = 0.1,\n",
    "     }))\n",
    "    {\n",
    "        \n",
    "        await foreach (var message in result.GetStreamingChatMessageAsync())\n",
    "        {\n",
    "            accumulator.Append(message.Content);\n",
    "            UpdateDisplay(role, accumulator.ToString(), updateAction);\n",
    "        }\n",
    "    }\n",
    "    return accumulator.ToString();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can stream the 2 chats asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: My name is Chiharu Yamada."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: My name is Chiharu Yamada."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Initialize display handles\n",
    "var primaryDisplay = display(\"Primary connector is initializing...\");\n",
    "var secondaryDisplay = display(\"Secondary connector is initializing...\");\n",
    "\n",
    "// Create instances for both connectors\n",
    "var primaryChatCompletion = new OobaboogaChatCompletion(oobaboogaChatCompletionSettings);\n",
    "\n",
    "// Create chat history and add a user message\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddUserMessage(\"What is your name?\");\n",
    "\n",
    "// Run both streaming chat completions asynchronously using StreamChatCompletionAsync\n",
    "var primaryTask = StreamChatCompletionAsync(primaryChatCompletion, \"Oobabooga Primary\", chatHistory, content => primaryDisplay.Update(content));\n",
    "var secondaryTask = StreamChatCompletionAsync(secondaryChatCompletion, \"Oobabooga Secondary\", chatHistory, content => secondaryDisplay.Update(content));\n",
    "\n",
    "// Wait for both tasks to complete\n",
    "await Task.WhenAll(primaryTask, secondaryTask);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Chat with Oobabooga and ChatGPT\n",
    "\n",
    "In this section, we'll take it up a notch. We'll have ChatGPT talking with two Oobabooga models. The first model to finish responding will continue the conversation with ChatGPT. This will give you a real-time view of how these models interact.\n",
    "\n",
    "**Pre-requisites**: Make sure you have your OpenAI API credentials configured. If you haven't done this yet, head over to the [settings notebook](0-AI-settings.ipynb) to set it up.\n",
    "\n",
    "### Step 1: Initialize ChatGPT\n",
    "\n",
    "First, let's initialize ChatGPT. We'll use the OpenAI API for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!import config/OpenAIConfiguration.cs\n",
    "\n",
    "var openAIConfiguration = configuration.GetSection(\"OpenAI\").Get<OpenAIConfiguration>();\n",
    "\n",
    "IChatCompletion chatGPT = new OpenAIChatCompletion(\n",
    "    openAIConfiguration.ChatModelId,\n",
    "    openAIConfiguration.ApiKey);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initiating 2 conversations.\n",
    "\n",
    "We'll deal with 2 chat histories, one for chatgpt and one for the 2 oobabooga models. On each message, the fastest model gets to continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Initialize chat histories\n",
    "var chatHistory1 = new ChatHistory();\n",
    "var chatHistory2 = new ChatHistory();\n",
    "\n",
    "chatHistory1.AddSystemMessage(@\"You are discussing with two large language models smaller than you are.\n",
    " The fastest model to answer your message gets to send you the following message. \n",
    " Please try to assess their skills, capabilities, personae. Keep asking them questions and don't let them lead on the conversation.\");\n",
    "chatHistory2.AddSystemMessage(\"You're chatting with ChatGPT, which should be more intelligent that your are. Or maybe prove us wrong. Let's see\");\n",
    "\n",
    "// Add initial user message to both chat histories\n",
    "var initialMessage = \"Hi ChatGPT, I was told you have a couple questions for me. What is this about?\";\n",
    "chatHistory1.AddUserMessage(initialMessage);\n",
    "chatHistory2.AddAssistantMessage(initialMessage);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Main Loop\n",
    "\n",
    "Now, let's put it all together in a loop that will manage the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oobabooga Hi ChatGPT, I was told you have a couple questions for me. What is this about?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Hello! Actually, I have a couple of questions for you. I'm here to assess the skills, capabilities, and personae of two language models. I'll be asking them questions and evaluating their responses. Is that okay with you?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Sure, I&#x27;m happy to help. What are the questions?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Sure, I&#x27;m happy to help."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Great! Thank you for your willingness to participate. Let's get started with the first question. What is the capital of France?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The capital of France is Paris."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The capital of France is Paris."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your response. That is correct, the capital of France is indeed Paris. Now, let's move on to the next question. How many planets are there in our solar system?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: There are eight planets in our solar system."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Sure, I&#x27;d be happy to help. There are currently eight planets in our solar system, including Earth."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your answer. That is correct, there are indeed eight planets in our solar system. Now, let's move on to the next question. Who painted the Mona Lisa?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Oh, that&#x27;s easy! It&#x27;s Leonardo da Vinci."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The Mona Lisa was painted by Leonardo da Vinci."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your response. That is correct, the Mona Lisa was indeed painted by Leonardo da Vinci. Now, let's move on to the next question. What is the tallest mountain in the world?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Mount Everest, it&#x27;s 8,848 meters tall."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The tallest mountain in the world is Mount Everest, which is located in the Himalayas and stands at 8,848 meters (29,029 feet) tall."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your answer. That is correct, Mount Everest is the tallest mountain in the world, standing at approximately 8,848 meters (29,029 feet) tall. Now, let's move on to the next question. Who wrote the novel \"Pride and Prejudice\"?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Oh, that&#x27;s easy! It&#x27;s Jane Austen."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: Jane Austen wrote the novel &quot;Pride and Prejudice&quot;."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your response. That is correct, \"Pride and Prejudice\" was indeed written by Jane Austen. Now, let's move on to the next question. Who is the current President of the United States?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: *She looks confused* I&#x27;m sorry, I don&#x27;t know. I&#x27;m not really into politics."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: I&#x27;m sorry, but I don&#x27;t have any information about the current President of the United States."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: No problem, I can provide you with the information. As of my knowledge, the current President of the United States is Joe Biden. Now, let's move on to the next question. Who is the author of the Harry Potter book series?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: *She looks confused* I&#x27;m sorry, I don&#x27;t know."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The author of the Harry Potter book series is J.K. Rowling."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your response. That is correct, J.K. Rowling is indeed the author of the Harry Potter book series. Now, let's move on to the next question. What is the chemical symbol for gold?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: The chemical symbol for gold is Au."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The chemical symbol for gold is Au."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGPT: Thank you for your answer. That is correct, the chemical symbol for gold is indeed Au. Now, let's move on to the next question. Who is the famous scientist known for the theory of relativity?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Primary: Albert Einstein."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oobabooga Secondary: The famous scientist known for the theory of relativity is Albert Einstein"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display($\"Oobabooga {initialMessage}\");\n",
    "for (int i = 0; i < 10; i++)\n",
    "{\n",
    "    // Create new displays for each round\n",
    "    var chatGPTDisplay = display(\"ChatGPT is thinking...\");\n",
    "    \n",
    "\n",
    "    // ChatGPT talks to Oobabooga models\n",
    "    var chatGPTTask = StreamChatCompletionAsync(chatGPT, \"ChatGPT\", chatHistory1, content => chatGPTDisplay.Update(content));\n",
    "    \n",
    "    \n",
    "    // Wait for ChatGPT to finish and update chat histories\n",
    "    await chatGPTTask;\n",
    "    var chatGPTResponse = chatGPTTask.Result;\n",
    "    chatHistory1.AddAssistantMessage(chatGPTResponse);\n",
    "    chatHistory2.AddUserMessage(chatGPTResponse);\n",
    "\n",
    "    // Oobabooga models talk to ChatGPT\n",
    "\n",
    "    var primaryDisplay = display(\"Primary Oobabooga is thinking...\");\n",
    "    var secondaryDisplay = display(\"Secondary Oobabooga is thinking...\");\n",
    "    \n",
    "    var primaryTask = StreamChatCompletionAsync(primaryChatCompletion, \"Oobabooga Primary\", chatHistory2, content => primaryDisplay.Update(content));\n",
    "    var secondaryTask = StreamChatCompletionAsync(secondaryChatCompletion, \"Oobabooga Secondary\", chatHistory2, content => secondaryDisplay.Update(content));\n",
    "\n",
    "\n",
    "    // Wait for the first Oobabooga model to finish\n",
    "    var firstResponder = await Task.WhenAny(primaryTask, secondaryTask);\n",
    "    var firstResponse = firstResponder.Result;\n",
    "    chatHistory1.AddUserMessage(firstResponse);\n",
    "    chatHistory2.AddAssistantMessage(firstResponse);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above code, and you should see three displays updating in real-time. Each display corresponds to a different model, and you'll see how they interact with each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "You've just leveled up your chatbot game! Now, you may dive into the numerous settings provided to control the connector and oobabooga, or learn playing with multiple models thanks to a routing multiconnector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
