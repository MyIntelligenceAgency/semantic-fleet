{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Multi-Connector Optimization with Explicit Summarization Prompts\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this notebook, we'll focus on demonstrating the optimization capabilities of our multi-connector setup. We'll use a simple, explicit summarization prompt to illustrate how the system can optimize the selection of connectors for specific tasks by offloading the summarization skill from ChatGPT to smaller Oobabooga models.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Before proceeding, make sure you have run `00-AI-settings.ipynb` to set up your OpenAI key, since we'll use ChatGPT as our primary connector, and have at least one Oobabooga model running and configured in the `Multiconnector` section of your `settings.json` file according to your VRam capabilities.\n",
    "- Basic knowledge of the multi-connector pipeline from `03-multiConnector-intro-with-arithmetic-mocks.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Import Required Libraries\n",
    "\n",
    "We'll start with importing the appropriate Nugget packages to load the configuration settings, and to run the Multiconnector itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 7.0.0</span></li><li><span>Microsoft.Extensions.Configuration.Binder, 7.0.4</span></li><li><span>Microsoft.Extensions.Configuration.Json, 7.0.0</span></li><li><span>Microsoft.SemanticKernel, 0.24.230918.1-preview</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.MultiConnector, 0.33.8</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.Oobabooga, 0.33.8</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Import package for loading hierarchichal settings from settings.json\n",
    "#r \"nuget: Microsoft.Extensions.Configuration\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Binder\"\n",
    "\n",
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 0.24.230918.1-preview\"\n",
    "// Import Oobabooga connector package\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.Oobabooga\"\n",
    "// Import Multiconnector package\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.MultiConnector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Settings\n",
    "\n",
    "We load OpenAi and Multiconnector configuration from the settings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Load configuration using builder package\n",
    "using System.IO;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration;\n",
    "\n",
    "var builder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"config/settings.json\", optional: false, reloadOnChange: true);\n",
    "\n",
    "IConfiguration configuration = builder.Build();\n",
    "\n",
    "var openAIConfiguration = configuration.GetSection(\"OpenAI\").Get<OpenAIConfiguration>();\n",
    "var multiOobaboogaConnectorConfiguration = configuration.GetSection(\"MultiConnector\").Get<MultiOobaboogaConnectorConfiguration>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set up MultiTextCompletion settings\n",
    "\n",
    "There are many parameters controlling how the multiconnector will work and perform optimization. We need to create an instance of the corresponding class.\n",
    "\n",
    "Also, because we'll be measuring costs to perform our optimization, we need to create an creditor object dedicated to that.\n",
    "\n",
    "For now, we'll stick to the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\r\n",
       "  \"FreezePromptTypes\": false,\r\n",
       "  \"PromptTruncationLength\": 20,\r\n",
       "  \"AdjustPromptStarts\": false,\r\n",
       "  \"EnablePromptSampling\": true,\r\n",
       "  \"MaxInstanceNb\": 10,\r\n",
       "  \"AnalysisSettings\": {\r\n",
       "    \"EnableAnalysis\": false,\r\n",
       "    \"AnalysisFilePath\": \".\\\\MultiTextCompletion-analysis.json\",\r\n",
       "    \"AnalysisDelay\": \"00:00:01\",\r\n",
       "    \"AnalysisAwaitsManualTrigger\": false,\r\n",
       "    \"EnableConnectorTests\": true,\r\n",
       "    \"TestPrimaryCompletion\": true,\r\n",
       "    \"TestsPeriod\": \"00:00:10\",\r\n",
       "    \"MaxDegreeOfParallelismTests\": 1,\r\n",
       "    \"MaxDegreeOfParallelismConnectorsByTest\": 3,\r\n",
       "    \"EnableTestEvaluations\": true,\r\n",
       "    \"EvaluationPeriod\": \"00:00:10\",\r\n",
       "    \"MaxDegreeOfParallelismEvaluations\": 5,\r\n",
       "    \"UseSelfVetting\": false,\r\n",
       "    \"EnableSuggestion\": true,\r\n",
       "    \"SuggestionPeriod\": \"00:01:00\",\r\n",
       "    \"UpdateSuggestedSettings\": true,\r\n",
       "    \"SaveSuggestedSettings\": false,\r\n",
       "    \"DeleteAnalysisFile\": true,\r\n",
       "    \"MultiCompletionSettingsFilePath\": \".\\\\MultiTextCompletionSettings.json\",\r\n",
       "    \"NbPromptTests\": 3,\r\n",
       "    \"VettingPromptTransform\": {\r\n",
       "      \"Template\": \"Validate a text completion model\\u0027s response to a semantic function: following are a templated prompt sent to a large language model and the completion it returned, to be evaluated. Please indicate whether the response is valid or not.\\n{SemanticRemarks}\\nDoes the reponse appropriately completes the prompt? Please answer simply with true or false.\\nPROMPT:\\n-------\\n{prompt}\\nRESPONSE:\\n---------\\n{0}\\nRESPONSE IS VALID? (true/false):\\n--------------------------------\\n\",\r\n",
       "      \"InterpolationType\": 1\r\n",
       "    },\r\n",
       "    \"VettingRequestSettings\": {\r\n",
       "      \"Temperature\": 0,\r\n",
       "      \"TopP\": 0,\r\n",
       "      \"PresencePenalty\": 0,\r\n",
       "      \"FrequencyPenalty\": 0,\r\n",
       "      \"MaxTokens\": 1,\r\n",
       "      \"StopSequences\": [],\r\n",
       "      \"ResultsPerPrompt\": 1,\r\n",
       "      \"ChatSystemPrompt\": \"Assistant is a large language model.\",\r\n",
       "      \"TokenSelectionBiases\": {}\r\n",
       "    }\r\n",
       "  },\r\n",
       "  \"LogCallResult\": false,\r\n",
       "  \"LogTestCollection\": false,\r\n",
       "  \"PromptLogsJsonEncoded\": true,\r\n",
       "  \"PromptLogTruncationLength\": 2000,\r\n",
       "  \"PromptLogTruncationFormat\": \"{0}  (...)   {1}\",\r\n",
       "  \"PromptMultiConnectorSettings\": [],\r\n",
       "  \"GlobalParameters\": {\r\n",
       "    \"SystemSupplement\": \"Assume you\\u0027re about to engage in the \\u0027semantic-function game\\u0027. In this context, every incoming prompt will be based on a semantic function, even if it\\u0027s not perfectly formed or seems ambiguous. Your primary goal is to identify and execute the core function or intent of the message, filtering out noise or extraneous details. Treat the following prompt as a function and provide a direct, precise completion without added commentary. Prioritize the most likely and salient function based on the information presented. Be alert to cues, even if they\\u0027re subtle or embedded, and strive to respond as accurately and succinctly as possible.\",\r\n",
       "    \"UserPreamble\": \"Let\\u0027s engage in a game: carefully heed the upcoming directives. Respond solely with a continuation of my message, abstaining from any extra remarks.\",\r\n",
       "    \"SemanticRemarks\": \"Semantic functions are structured templates that work in tandem with other similar templates and native code-based functions. The native functions, in particular, demand a precise adherence to given instructions. They rely heavily on accurately parsed input parameters and lack mechanisms to sift through any unnecessary noise.\\nWhen assessing the appropriateness of a response, it\\u0027s crucial to be discerning. While instructions often present an example that outlines the desired response format, these examples may not always be exhaustive. Occasionally, they might even be overly simplistic, intended merely to keep the instructions concise. Thus, always ensure that you thoroughly understand and thoughtfully apply these instructions to generate a fitting answer to the given input.\"\r\n",
       "  },\r\n",
       "  \"GlobalPromptTransform\": null,\r\n",
       "  \"Creditor\": {\r\n",
       "    \"OngoingCost\": 0\r\n",
       "  },\r\n",
       "  \"SampleCollectionDelay\": \"00:00:00.0200000\",\r\n",
       "  \"SampleVettedConnectors\": true\r\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector;\n",
    "using System.Text.Json;\n",
    "using System.Text.Json.Serialization;\n",
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector.PromptSettings;\n",
    "\n",
    "var creditor = new CallRequestCostCreditor();\n",
    "\n",
    "// The most common settings for a MultiTextCompletion are illustrated below, most of them have default values and are optional\n",
    "var settings = new MultiTextCompletionSettings()\n",
    "{\n",
    "    Creditor = creditor\n",
    "};\n",
    "\n",
    "string jsonString = JsonSerializer.Serialize(settings, new JsonSerializerOptions() { WriteIndented = true });\n",
    "display(jsonString);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization\n",
    "\n",
    "With all the settings created, we can now create the semantic kernel that we'll use to run our tests.\n",
    "\n",
    "### 2.1 Create primary and secondary completions\n",
    "\n",
    "We'll use the OpenAi configuration to instantiate a text or chat based connector typically using ChatGPT.\n",
    "Then we can use a helper method from the multicompletion configuration to instantiate all Oobabooga secondary connectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of secondary completions created: 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System.Threading;\n",
    "using Microsoft.SemanticKernel.AI.TextCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.TextCompletion;\n",
    "\n",
    "// Creating a cancellation token source to be able to cancel the request\n",
    "CancellationTokenSource cleanupToken = new();\n",
    "\n",
    "//Creating the primary connector. We use the OpenAI connector here, either text or chat completion depending on the configuration\n",
    " ITextCompletion openAiConnector;\n",
    "\n",
    " string testOrChatModelId;\n",
    " if (openAIConfiguration.ChatModelId != null)\n",
    " {\n",
    "     testOrChatModelId = openAIConfiguration.ChatModelId;\n",
    "     openAiConnector = new OpenAIChatCompletion(testOrChatModelId, openAIConfiguration.ApiKey);\n",
    " }\n",
    " else\n",
    " {\n",
    "     testOrChatModelId = openAIConfiguration.ModelId;\n",
    "     openAiConnector = new OpenAITextCompletion(testOrChatModelId, openAIConfiguration.ApiKey);\n",
    " }\n",
    "\n",
    " // Creating the corresponding named completion\n",
    " var openAiNamedCompletion = new NamedTextCompletion(testOrChatModelId, openAiConnector)\n",
    "{\n",
    "    MaxTokens = openAIConfiguration.MaxTokens,\n",
    "    CostPer1000Token = openAIConfiguration.CostPer1000Token,\n",
    "    TokenCountFunc = MultiOobaboogaConnectorConfiguration.TokenCountFunctionMap[openAIConfiguration.TokenCountFunction],\n",
    "    //We did not observe any limit on Open AI concurrent calls\n",
    "    MaxDegreeOfParallelism = 5,\n",
    "};\n",
    "\n",
    " // Creating the secondary connectors. We use a dedicated helper, but you can create them manually if you want.\n",
    " var oobaboogaCompletions = multiOobaboogaConnectorConfiguration.CreateNamedCompletions();\n",
    "\n",
    " display($\"Number of secondary completions created: {oobaboogaCompletions.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Kernel\n",
    "\n",
    "Now that we have our primary and secondary completions, we can create a semantic kernel and instantiate our multiconnector from settings and completions.\n",
    "\n",
    "We use the dedicated helper for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var builder = Microsoft.SemanticKernel.Kernel.Builder;\n",
    "\n",
    "builder.WithMultiConnectorCompletionService(\n",
    "    serviceId: null,\n",
    "    settings: settings,\n",
    "    mainTextCompletion: openAiNamedCompletion,\n",
    "    setAsDefault: true,\n",
    "    analysisTaskCancellationToken: cleanupToken.Token,\n",
    "    otherCompletions: oobaboogaCompletions.ToArray());\n",
    "\n",
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create simple inline semantic function\n",
    "\n",
    "For this first example, we concentrate on offloading a single simple parameter-less semantic function. \n",
    "\n",
    "In the next notebook, we'll move on with considering skills, inputs of various complexities, static and finally dynamic plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "var text = @\"A long time ago, people wanted to tell others their stories. First, they wrote letters with their hands. They would send these letters to friends far away. Sometimes, people waited a lot of days to get a letter.\n",
    "\n",
    "After that, a big machine called the printing press was made. It could make many copies of a story quickly. More people could read the same thing without waiting.\n",
    "\n",
    "Next, there was a telephone. With it, people could talk and listen to friends who were far. They didn’t have to wait for letters anymore.\n",
    "\n",
    "Then, there was a thing called television. People could watch stories on it, like a play. They didn’t need to go outside.\n",
    "\n",
    "Lastly, came mobile phones and computers. People could send messages fast. With the internet, they could also use something called social media to share stories with many people at once.\";\n",
    "\n",
    "var prompt = $\"Summarize the following text in one sentence:\\n{text}\\n\\nSummary:\";\n",
    "\n",
    "var simpleSemanticFunction = kernel.CreateSemanticFunction(prompt, maxTokens: 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running and optimizing settings\n",
    "\n",
    "Now that everything is in order we'll follow the following workflow:\n",
    "\n",
    "- The plan is run once. The primary connector defined (Chat GPT) is used to generate our completion.\n",
    "    - Performance in cost and in duration is recorded.\n",
    "    - Samples are collected automatically during the run\n",
    "    - Result of the plan is shown.\n",
    "- An analysis task is run from samples collected during the run.\n",
    "    - Each connector is tested on the samples.\n",
    "    - The primary connector (ChatGPT) evaluates the test runs, vetting each connector's capability to handle each corresponding prompt type.\n",
    "    - New settings are computed from the evaluation. Vetted connectors are promoted to handle the corresponding prompt types.\n",
    "    - MultiCompletion settings are updated according to the analysis results.\n",
    "- The original plan is reloaded and run again. This time, the secondary connectors may be used to generate some or all of the completions according to the updated settings.\n",
    "    - Performance in cost and in duration is recorded.\n",
    "    - Result of the plan is shown\n",
    "\n",
    "### 3.1 Run function with Primary Connector\n",
    "\n",
    "For this first example, we want our multiconnector to do the job automatically for us, so we'll configure our settings accordingly before we run our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "settings.EnablePromptSampling = true;\n",
    "settings.AnalysisSettings.EnableAnalysis = true;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
