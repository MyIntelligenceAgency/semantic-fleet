{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Multi-Connector Optimization with Explicit Summarization Prompts\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this notebook, we'll focus on demonstrating the optimization capabilities of our multi-connector setup. We'll use a simple, explicit summarization prompt to illustrate how the system can optimize the selection of connectors for specific tasks by offloading the summarization skill from ChatGPT to smaller Oobabooga models.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Before proceeding, make sure you have run `00-AI-settings.ipynb` to set up your OpenAI key, since we'll use ChatGPT as our primary connector, and have at least one Oobabooga model running and configured in the `Multiconnector` section of your `settings.json` file according to your VRam capabilities.\n",
    "- Basic knowledge of the multi-connector pipeline from `03-multiConnector-intro-with-arithmetic-mocks.ipynb`.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Setup**\n",
    "    - Import required libraries\n",
    "    - Load configuration from settings file\n",
    "    - Create multicompletion settings\n",
    "2. **Initialization**\n",
    "    - Initialize the kernel with multicompletion settings\n",
    "    - Import summarization skill\n",
    "3. **Creating a Simple Explicit Summarization Prompt**\n",
    "    - Define the prompt\n",
    "    - Create a plan\n",
    "4. **First Pass: Primary Connector**\n",
    "    - Execute the plan with the primary connector\n",
    "    - Analyze the cost and duration\n",
    "5. **Optimization**\n",
    "    - Perform tests, evaluation, and optimization\n",
    "6. **Second Pass: Updated Settings**\n",
    "    - Re-execute the plan with optimized settings\n",
    "    - Compare the results\n",
    "7. **Conclusion**\n",
    "    - Summary of findings\n",
    "    - Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Import Required Libraries\n",
    "\n",
    "We'll start with importing the appropriate Nugget packages to load the configuration settings, and to run the Multiconnector itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 7.0.0</span></li><li><span>Microsoft.Extensions.Configuration.Binder, 7.0.4</span></li><li><span>Microsoft.Extensions.Configuration.Json, 7.0.0</span></li><li><span>Microsoft.SemanticKernel, 0.24.230918.1-preview</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.MultiConnector, 0.33.8</span></li><li><span>MyIA.SemanticKernel.Connectors.AI.Oobabooga, 0.33.8</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Import package for loading hierarchichal settings from settings.json\n",
    "#r \"nuget: Microsoft.Extensions.Configuration\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Binder\"\n",
    "\n",
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 0.24.230918.1-preview\"\n",
    "// Import Oobabooga connector package\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.Oobabooga\"\n",
    "// Import Multiconnector package\n",
    "#r \"nuget: MyIA.SemanticKernel.Connectors.AI.MultiConnector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Settings\n",
    "\n",
    "We load OpenAi and Multiconnector configuration from the settings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Load configuration using builder package\n",
    "using System.IO;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration;\n",
    "\n",
    "var builder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"config/settings.json\", optional: false, reloadOnChange: true);\n",
    "\n",
    "IConfiguration configuration = builder.Build();\n",
    "\n",
    "var openAIConfiguration = configuration.GetSection(\"OpenAI\").Get<OpenAIConfiguration>();\n",
    "var multiOobaboogaConnectorConfiguration = configuration.GetSection(\"MultiConnector\").Get<MultiOobaboogaConnectorConfiguration>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set up MultiTextCompletion settings\n",
    "\n",
    "There are many parameters controlling how the multiconnector will work and perform optimization. We need to create an instance of the corresponding class.\n",
    "\n",
    "Also, because we'll be measuring costs to perform our optimization, we need to create an creditor object dedicated to that.\n",
    "\n",
    "For now, we'll stick to the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\r\n",
       "  \"FreezePromptTypes\": false,\r\n",
       "  \"PromptTruncationLength\": 20,\r\n",
       "  \"AdjustPromptStarts\": false,\r\n",
       "  \"EnablePromptSampling\": true,\r\n",
       "  \"MaxInstanceNb\": 10,\r\n",
       "  \"AnalysisSettings\": {\r\n",
       "    \"EnableAnalysis\": false,\r\n",
       "    \"AnalysisFilePath\": \".\\\\MultiTextCompletion-analysis.json\",\r\n",
       "    \"AnalysisDelay\": \"00:00:01\",\r\n",
       "    \"AnalysisAwaitsManualTrigger\": false,\r\n",
       "    \"EnableConnectorTests\": true,\r\n",
       "    \"TestPrimaryCompletion\": true,\r\n",
       "    \"TestsPeriod\": \"00:00:10\",\r\n",
       "    \"MaxDegreeOfParallelismTests\": 1,\r\n",
       "    \"MaxDegreeOfParallelismConnectorsByTest\": 3,\r\n",
       "    \"EnableTestEvaluations\": true,\r\n",
       "    \"EvaluationPeriod\": \"00:00:10\",\r\n",
       "    \"MaxDegreeOfParallelismEvaluations\": 5,\r\n",
       "    \"UseSelfVetting\": false,\r\n",
       "    \"EnableSuggestion\": true,\r\n",
       "    \"SuggestionPeriod\": \"00:01:00\",\r\n",
       "    \"UpdateSuggestedSettings\": true,\r\n",
       "    \"SaveSuggestedSettings\": false,\r\n",
       "    \"DeleteAnalysisFile\": true,\r\n",
       "    \"MultiCompletionSettingsFilePath\": \".\\\\MultiTextCompletionSettings.json\",\r\n",
       "    \"NbPromptTests\": 3,\r\n",
       "    \"VettingPromptTransform\": {\r\n",
       "      \"Template\": \"Validate a text completion model\\u0027s response to a semantic function: following are a templated prompt sent to a large language model and the completion it returned, to be evaluated. Please indicate whether the response is valid or not.\\n{SemanticRemarks}\\nDoes the reponse appropriately completes the prompt? Please answer simply with true or false.\\nPROMPT:\\n-------\\n{prompt}\\nRESPONSE:\\n---------\\n{0}\\nRESPONSE IS VALID? (true/false):\\n--------------------------------\\n\",\r\n",
       "      \"InterpolationType\": 1\r\n",
       "    },\r\n",
       "    \"VettingRequestSettings\": {\r\n",
       "      \"Temperature\": 0,\r\n",
       "      \"TopP\": 0,\r\n",
       "      \"PresencePenalty\": 0,\r\n",
       "      \"FrequencyPenalty\": 0,\r\n",
       "      \"MaxTokens\": 1,\r\n",
       "      \"StopSequences\": [],\r\n",
       "      \"ResultsPerPrompt\": 1,\r\n",
       "      \"ChatSystemPrompt\": \"Assistant is a large language model.\",\r\n",
       "      \"TokenSelectionBiases\": {}\r\n",
       "    }\r\n",
       "  },\r\n",
       "  \"LogCallResult\": false,\r\n",
       "  \"LogTestCollection\": false,\r\n",
       "  \"PromptLogsJsonEncoded\": true,\r\n",
       "  \"PromptLogTruncationLength\": 2000,\r\n",
       "  \"PromptLogTruncationFormat\": \"{0}  (...)   {1}\",\r\n",
       "  \"PromptMultiConnectorSettings\": [],\r\n",
       "  \"GlobalParameters\": {\r\n",
       "    \"SystemSupplement\": \"Assume you\\u0027re about to engage in the \\u0027semantic-function game\\u0027. In this context, every incoming prompt will be based on a semantic function, even if it\\u0027s not perfectly formed or seems ambiguous. Your primary goal is to identify and execute the core function or intent of the message, filtering out noise or extraneous details. Treat the following prompt as a function and provide a direct, precise completion without added commentary. Prioritize the most likely and salient function based on the information presented. Be alert to cues, even if they\\u0027re subtle or embedded, and strive to respond as accurately and succinctly as possible.\",\r\n",
       "    \"UserPreamble\": \"Let\\u0027s engage in a game: carefully heed the upcoming directives. Respond solely with a continuation of my message, abstaining from any extra remarks.\",\r\n",
       "    \"SemanticRemarks\": \"Semantic functions are structured templates that work in tandem with other similar templates and native code-based functions. The native functions, in particular, demand a precise adherence to given instructions. They rely heavily on accurately parsed input parameters and lack mechanisms to sift through any unnecessary noise.\\nWhen assessing the appropriateness of a response, it\\u0027s crucial to be discerning. While instructions often present an example that outlines the desired response format, these examples may not always be exhaustive. Occasionally, they might even be overly simplistic, intended merely to keep the instructions concise. Thus, always ensure that you thoroughly understand and thoughtfully apply these instructions to generate a fitting answer to the given input.\"\r\n",
       "  },\r\n",
       "  \"GlobalPromptTransform\": null,\r\n",
       "  \"Creditor\": {\r\n",
       "    \"OngoingCost\": 0\r\n",
       "  },\r\n",
       "  \"SampleCollectionDelay\": \"00:00:00.0200000\",\r\n",
       "  \"SampleVettedConnectors\": true\r\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector;\n",
    "using System.Text.Json;\n",
    "using System.Text.Json.Serialization;\n",
    "using MyIA.SemanticKernel.Connectors.AI.MultiConnector.PromptSettings;\n",
    "\n",
    "var creditor = new CallRequestCostCreditor();\n",
    "\n",
    "// The most common settings for a MultiTextCompletion are illustrated below, most of them have default values and are optional\n",
    "var settings = new MultiTextCompletionSettings()\n",
    "{\n",
    "    Creditor = creditor\n",
    "};\n",
    "\n",
    "string jsonString = JsonSerializer.Serialize(settings, new JsonSerializerOptions() { WriteIndented = true });\n",
    "display(jsonString);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization\n",
    "\n",
    "With all the settings created, we can now create the semantic kernel that we'll use to run our tests.\n",
    "\n",
    "### 2.1 Create primary and secondary completions\n",
    "\n",
    "We'll use the OpenAi configuration to instantiate a text or chat based connector typically using ChatGPT.\n",
    "Then we can use a helper method from the multicompletion configuration to instantiate all Oobabooga secondary connectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "System.UriFormatException: Invalid URI: The URI is empty.\r\n   at System.Uri.CreateThis(String uri, Boolean dontEscape, UriKind uriKind, UriCreationOptions& creationOptions)\r\n   at System.Uri..ctor(String uriString)\r\n   at MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration.OobaboogaConnectorConfiguration.CreateSettings(String defaultEndpoint, Func`1 webSocketFactory, ILoggerFactory loggerFactory)\r\n   at MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration.MultiOobaboogaConnectorConfiguration.CreateNamedCompletions(List`1 modelNames)\r\n   at Submission#5.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.UriFormatException: Invalid URI: The URI is empty.\r\n",
      "   at System.Uri.CreateThis(String uri, Boolean dontEscape, UriKind uriKind, UriCreationOptions& creationOptions)\r\n",
      "   at System.Uri..ctor(String uriString)\r\n",
      "   at MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration.OobaboogaConnectorConfiguration.CreateSettings(String defaultEndpoint, Func`1 webSocketFactory, ILoggerFactory loggerFactory)\r\n",
      "   at MyIA.SemanticKernel.Connectors.AI.MultiConnector.Configuration.MultiOobaboogaConnectorConfiguration.CreateNamedCompletions(List`1 modelNames)\r\n",
      "   at Submission#5.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "using System.Threading;\n",
    "using Microsoft.SemanticKernel.AI.TextCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.TextCompletion;\n",
    "\n",
    "// Creating a cancellation token source to be able to cancel the request\n",
    "CancellationTokenSource cleanupToken = new();\n",
    "\n",
    "//Creating the primary connector. We use the OpenAI connector here, either text or chat completion depending on the configuration\n",
    " ITextCompletion openAiConnector;\n",
    "\n",
    " string testOrChatModelId;\n",
    " if (openAIConfiguration.ChatModelId != null)\n",
    " {\n",
    "     testOrChatModelId = openAIConfiguration.ChatModelId;\n",
    "     openAiConnector = new OpenAIChatCompletion(testOrChatModelId, openAIConfiguration.ApiKey);\n",
    " }\n",
    " else\n",
    " {\n",
    "     testOrChatModelId = openAIConfiguration.ModelId;\n",
    "     openAiConnector = new OpenAITextCompletion(testOrChatModelId, openAIConfiguration.ApiKey);\n",
    " }\n",
    "\n",
    " // Creating the secondary connectors. We use a dedicated helper, but you can create them manually if you want.\n",
    "\n",
    " var oobaboogaCompletions = multiOobaboogaConnectorConfiguration.CreateNamedCompletions();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Kernel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
